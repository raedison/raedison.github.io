---
title: "Project 2: Modeling, Testing, and Predicting with Pokemon"
author: "Ruth Edison (re6335)"
date: "5/6/2021"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
```


## Introduction

I decided to use the Pokemon dataset in R for this project since as a gamer, it seemed like a lot of fun to be able to bring my hobbies into class. My categorical variables are Generation since there are 6 generations of Pokemon, and Legendary status, or whether a given Pokemon is legendary or not. Technically, Generation registers as an integer column in the dataset, but as Generation is a title not a value, it still classifies as a categorical variable. I'd originally wanted to use their type, but since there are 18 Pokemon types that would be outside the scope of this project. My numeric variables are HP, Attack, Defense, Special Attack, Special Defense, and Speed stats. The dataset has 800 observations.

```{R}
library(tidyverse)
pokemon<-read.csv("http://www.nathanielwoodward.com/Pokemon.csv")
poke<-pokemon%>%select(Name, HP, Attack, Defense, "SpAtk"="Sp..Atk","SpDef"="Sp..Def",Speed, Generation, Legendary)
```

## MANOVA Testing

I performed a MANOVA test to check if any of numeric variables showed a mean difference across Pokemon generations. The first step was to check the assumptions. The data isn't randomly sampled, but I've looked past that, since it's a collection of facts for every single Pokemon in existence. Assumably, the values are taken as a mean since every individual Pokemon, even within species, has it's own unique set of statistics. The data is a collection of independent observations. Then I checked for multivariate normality of DVs. The first multivariate plot I made was with Attack and Defense stats by Generation. The plot showed multivariate normality between the variables.

```{R}
library(mvtnorm)
library(ggExtra)
ggplot(poke, aes(x= Attack, y = Defense))+geom_point(alpha=0.5)+geom_density_2d(h=2)+coord_fixed()+facet_wrap(~Generation)
```

The next multivariate plot I mad was with Special Attack and Special Defense stats by Generation.The plot showed multivariate normality between the variables.

```{R}
ggplot(poke, aes(x= SpAtk, y = SpDef))+geom_point(alpha=0.5)+geom_density_2d(h=2)+coord_fixed()+facet_wrap(~Generation)
```
The last multivariate plot I mad was with HP and Speed stats by Generation. The plot showed multivariate normality between the variables.

```{R}
ggplot(poke, aes(x= HP, y = Speed))+geom_point(alpha=0.5)+geom_density_2d(h=2)+coord_fixed()+facet_wrap(~Generation)
```
To formally test for multivariate normality, I performed the following procedure to obtain actual statistic values to prove the multivariate normality assumption. The null hypothesis for this test is that the normality assumption is met.

```{R}
library(rstatix)
group_gen <- poke$Generation
DVs <- poke%>%select(HP, Attack, Defense, SpAtk, SpDef, Speed)
sapply(split(DVs,group_gen),mshapiro_test)
```
Since the p-values are all less than 0.05, that means that the results are statistically significant and therefore the null hypothesis is rejected. Since it's hard to meet all the assumptions of MANOVA and each group had over 25 values in it, I continued on.

The next assumption to test for was homogeneity of within-group covariance matrices. For MANOVA tests, this mist be assumed for each DV and there must be covariance between any two DV. First, I created separate covariance matrices for each group.

```{R}
lapply(split(DVs,group_gen), cov)
```
After that, however, I decided to go with a more formal test of homogeneity of covariance using Box's M test. The null hypothesis was that the homogeneity of covariance assumption was met.

```{R}
box_m(DVs,group_gen)
```
The p-value was much lower than 0.05, so the null hypothesis was rejected, but since it's hard to meet all the assumptions of MANOVA, I continued on.

Since the statistics in question (HP, Attack, Defense, SpAtk, SpDef, Speed) are all independent assumptions, I assumed no linear relationships among the DVs. There were also no extreme univariate or multivariate outliers and no multicollinearity, so I continued on to the actual MANOVA test. My null hypothesis was that for each response variable, the means of all the generations were equal. My alternative hypothesis was that for at least one of my response variable, at least one of generation mean differs. 

```{R}
manova_gen<- manova(cbind(HP, Attack, Defense, SpAtk, SpDef, Speed)~Generation, data=poke)
summary(manova_gen)
```

The p-value of the MANOVA test is 0.435 which is larger than the significance value of 0.05, and therefore not statistically significant, so I accepted the null hypothesis. That means that for each of the response variables (HP, Attack, Defense, Special Attack, Special Defense, and Speed) the means of all the generations were equal. Therefore there was no need to run individual univariate ANOVA tests or post-hoc analyses. This was expected since each generation of Pokemon was introduced per new game so their stats overall would be expected to be on a similar level to those in a previous generation so as to avoid having overpowered characters and power creep.

## Randomization Testing

For my randomization test, I decided to run an F-statistic/ANOVA test to analyze the relationship between what Generation a given Pokemon is in and their Attack stat.

When checking assumptions, as stated before, the data isn't randomly sampled, but I've looked past that, since it's a collection of facts for every single Pokemon in existence and the data is a collection of independent observations. There are large samples, with more than 25 entries in each of the two groups, as there are 166 Pokemon in Gen 1, 106 in Gen 2, 160 in Gen 3, 121 in Gen 4, 165 in Gen 5, and 82 in Gen 6. When looking at the Equal Variance assumption, the standard deviation of Attack stats for Gen 1 Pokemon is 30.745,  32.708 for Gen 2, 36.594 for Gen 3, 32.781 for Gen 4, 30.366 for Gen 5, and 29.180 for Gen 6 which are all close to each other so the data passes that assumption.

```{R}
table(poke$Generation)
Gen1 <- poke[poke$Generation=="1",]
Gen2 <- poke[poke$Generation=="2",]
Gen3 <- poke[poke$Generation=="3",]
Gen4 <- poke[poke$Generation=="4",]
Gen5 <- poke[poke$Generation=="5",]
Gen6 <- poke[poke$Generation=="6",]
sd(Gen1$Attack)
sd(Gen2$Attack)
sd(Gen3$Attack)
sd(Gen4$Attack)
sd(Gen5$Attack)
sd(Gen6$Attack)
```

Then, I ran the F-statistic/ANOVA test. The null hypothesis us that the mean Attack stat for a Pokemon is equal regardless of Generation. The alternative hypothesis is that the mean Attack stat differs depending on what Generation a Pokemon is in.

```{R}
summary(aov(Attack~Generation,data=poke))
```

The results of the F-statistic/ANOVA test yielded a p-value of 0.146 which is greater than 0.05, so I failed to reject the null hypothesis meaning that there is no significant difference between the Attack statistic from Generation to Generation. Post-hoc tests weren't necessary since the null hypothesis was accepted.

Then I used a randomization test instead of the One-Way ANOVA.

```{R message=F}
obs_F <- 2.118
Fs <- replicate(5000,{
  new <- poke%>%mutate(Attack=sample(Attack))
  SSW <- new%>%group_by(Generation)%>%summarize(SSW=sum((Attack-mean(Attack))^2))%>%summarize(sum(SSW))%>%pull
  SSB <- new%>%mutate(mean=mean(Attack))%>%group_by(Generation)%>%mutate(groupmean=mean(Attack))%>%summarize(SSB=sum((mean-groupmean)^2))%>%summarize(sum(SSB))%>%pull
  (SSB/1)/(SSW/798)
})

hist(Fs, prob=T); abline(v=obs_F, col="red",add=T)
mean(Fs>obs_F)
```

The p-value obtained was 0.83 which is again greater than 0.05, leading to failing to reject the null hypothesis, meaning that there is no significant difference between the Attack statistic from Generation to Generation.

## Linear Regression without Bootstrapped Standard Errors

Next, I ran a linear regression test to observe the relationship of HP, Attack, Defense stats. I tested whether you can predict HP stats from Attack and Defense stats. The first null hypothesis was that while controlling for Attack stats, Defense stats do not explain variation in HP stats. The second null hypothesis was that while controlling for Defense stats, Attack stats do not explain variation in HP stats. Before running the test, I mean-centered all three numeric variables.

```{R}
poke$HP_c <- poke$HP - mean(poke$HP)
poke$Attack_c <- poke$Attack - mean(poke$Attack)
poke$Defense_c <- poke$Defense - mean(poke$Defense)
fit <- lm(HP_c~Attack_c*Defense_c, data = poke)
summary(fit)
```

The regression equation states that Mean Centered HP = -0.657 + 0.305(Centered Attack) + 0.054(Centered Defense). 0.305 is the slope for centered HP on centered Attack while holding centered Defense constant. 0.054 is the slope for centered HP on centered Defense while holding centered Attack constant. Then, I plotted the regression.

```{R}
new1<-poke
new1$Attack_c<-mean(poke$Attack_c)
new1$mean<-predict(fit,new1)
new1$Attack_c<-mean(poke$Attack_c)+sd(poke$Attack_c)
new1$plus.sd<-predict(fit,new1)
new1$Attack_c<-mean(poke$Attack_c)-sd(poke$Attack_c)
new1$minus.sd<-predict(fit,new1)
newint<-new1%>%select(HP_c,Defense_c,mean,plus.sd,minus.sd)%>%gather(Attack_c,value,-HP_c,-Defense_c)

mycols<-c("#619CFF","#F8766D","#00BA38")
names(mycols)<-c("-1 sd","mean","+1 sd")
mycols=as.factor(mycols)

ggplot(poke,aes(Defense_c,HP_c),group=mycols)+geom_point()+geom_line(data=new1,aes(y=mean,color="mean"))+geom_line(data=new1,aes(y=plus.sd,color="+1 sd"))+geom_line(data=new1,aes(y=minus.sd,color="-1 sd"))+scale_color_manual(values=mycols)+labs(color="Attack_c")+theme(legend.position=c(.9,.2))+ggtitle("Interaction Plot")
```

The proportion of variation in HP stats explained by Attack and Defense stats is the same as the R-squared value, which is 0.1836. 

Next I looked at the assumptions for the linear regression I just performed. I started with linearity, testing for this by plotting the relationship between the centered data for Attack and HP and then Defense and HP. Both distributions showed linearity. As mentioned in prior parts, the observations are independent and while the sampling isn't random, it's bypassable for this project.

```{R}
ggplot(poke, aes(x=Attack_c, y=HP_c)) + geom_point()
ggplot(poke, aes(x=Defense_c, y=HP_c)) + geom_point()
```

Then I checked for normally distributed residuals. Looking at the histogram of the residuals, the distribution looks normal. After this I tested for equal variance, or homoskedasticity. Observing the plot of the residuals vs. the fitted values, the variance could be more constant as there is a large area of dense grouping.

```{R}
resids<- lm(HP_c~Attack_c*Defense_c, data = poke)$residuals
ggplot()+geom_histogram(aes(resids),bins = 10)
fitted <- lm(HP_c~Attack_c*Defense_c, data = poke)$fitted.values
ggplot()+geom_point(aes(fitted,resids))
```

Then I recomputed regression results with robust standard errors due to not meeting the homoskedasticity assumption.

```{R}
library(sandwich)
library(lmtest)
fit_rse <- coeftest(fit,vcov=vcovHC(fit))[,1:2]
fit_rse
```

There are no real changes to the results of the linear regression, except for changes in the Standard Errors. The standard error of the intercept changed from 0.873 to 0.831. The standard error of the slope of the centered Attack stat changed from 0.028 to 0.035. The standard error of the slope of the centered Defense stat changed from 0.029 to 0.034. This makes sure that all the assumptions are met for the linear regression.

## Linear Regression with Bootstrapped Standard Errors

Then I reran the same linear regression but with bootstrapped standard errors.

```{R}
samp_distn<-replicate(5000, {
  boot_dat <-sample_frac(poke, replace = T)
  fit_boot <- lm(HP_c~Attack_c*Defense_c, data = boot_dat)
  coef(fit_boot)
})
samp_distn%>%t%>%as.data.frame%>%summarize_all(sd)

resids_boot <-fit$residuals
fitted_boot <-fit$fitted.values
resid_resamp <- replicate(5000,{
  new_resids <- sample(resids_boot,replace = TRUE)
  poke$new_y<-fitted_boot+new_resids
  fit_boot <-lm(new_y~Attack_c*Defense_c,data = poke)
  coef(fit_boot)
})
resid_resamp%>%t%>%as.data.frame%>%summarize_all(sd)

```

The bootstrapped SEs are 0.8735 for the intercept, 0.0282 for the centered attack stat, 0.0287 for the centered defense stat. The bootstrapped SE for the intercept increased from the robust standard error and is slightly larger than the original unaltered standard error/ The bootstrapped SE for the centered attack stat decreased from the robust standard error, but increased slightly from the unaltered standard error. The bootstrapped SE for the centered defense stat decreased compared to both the robust and unaltered standard errors. 

## Logistic Regression: Predicting a binary variable from two explanatory variable (with no interaction)

Next I fitted a logistic regression model predicting the binary variable of whether a Pokemon is Legendary or not from Special Attack and Special Defense. I chose not to include interaction in the model.

```{R}
fit_log <-glm(Legendary~SpAtk+SpDef, family = "binomial",data = poke)
fit_log_coef <- coeftest(fit_log)
coef(fit_log)%>%round(5)%>%data.frame
```

The equation generated from this is log(odds)= -9.953 + 0.045(Special Attack) + 0.037(Special Defense). Then this can be changed into odds=0.00005x1.046^(Special Attack)x1.038^(Special Defense). Holding Special Defense constant, going up one Special Attack stat multiplies odds by a factor of 1.046. Holding Special Attack constant, going up one Special Defense stat multiplies odds by a factor of 1.038. Then, I reported a confusion matrix for my logistic regression.

```{R}
probs_log<-predict(fit_log,type = "response")

class_diag <- function(probs,truth){ 
  if(is.character(truth)==TRUE) truth<-as.factor(truth) 
  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1 
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),factor(truth, levels=c(0,1))) 
  acc=sum(diag(tab))/sum(tab) 
  sens=tab[2,2]/colSums(tab)[2] 
  spec=tab[1,1]/colSums(tab)[1] 
  ppv=tab[2,2]/rowSums(tab)[2]
  ord<-order(probs, decreasing=TRUE) 
  probs <- probs[ord]; truth <- truth[ord] 
  TPR=cumsum(truth)/max(1,sum(truth))  
  FPR=cumsum(!truth)/max(1,sum(!truth)) 
  dup <-c(probs[-1]>=probs[-length(probs)], FALSE) 
  TPR <-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1) 
  n <- length(TPR) 
  auc <- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n])) 
  data.frame(acc,sens,spec,ppv,auc) 
}
class_diag(probs_log,poke$Legendary)
```

The accuracy of the model is 0.93 which is good. The sensitivity, which is the true positive rate, or the probability of a Pokemon being Legendary if they really are when predicted from Special Attack and Special Defense is 20/65=0.308. The specificity, which is the true negative rate, or the probability of a Pokemon being labeled as Legendary when they aren't when predicted from Special Attack and Special Defense is 724/735=0.985. The Precision, which is the PPV, or the proportion of Pokemon classified as Legendary that actually are from Special Attack and Special Defense is 20/31=0.645. The AUC is 0.931 which means that the probability of a randomly selected Legendary Pokemon has a higher Special Attack and Special Defense than a randomly selected non-Legendary Pokemon. Next, I made a density plot of the log-odds colored by the Legendary status of a Pokemon.

```{R}
poke$logit<-predict(fit_log,type = "link")
poke%>%ggplot()+geom_density(aes(logit,color=Legendary,fill=Legendary),alpha=0.4)+theme(legend.position=c(0.85,0.85))+geom_vline(xintercept = 0)+xlab("predictor(logit)")+ggtitle("Density Plot of the log-odds")
```

Then I generated an ROC curve and calculated the AUC from that.

```{R}
library(plotROC)
ROCplot1<-ggplot(poke)+geom_roc(aes(d=Legendary,m=SpAtk+SpDef),n.cuts = 0)+geom_segment(aes(x=0,xend=1,y=0,yend=1),lty=2) + ggtitle("ROC Plot for Legendary Status predicted from Special Attack and Special Defense Stats")
ROCplot1
calc_auc(ROCplot1)
```

The AUC for the ROC plot is 0.93. This means that 93% of the time, Legendary Pokemon will have higher Special Attack and Special Defense stats than non-Legendary Pokemon.

## Logistic Regression: Predicting a binary variable from all of the explanatory variables

Finally, I performed a logistic regression predicting Legendary Pokemon status from all of the other variables (HP, Attack, Defense, Special Attack, Special Defense, Speed, and Generation). First, I needed a dataset that didn't have the Name column, so I created a new dataset called "pokeclean." 

```{R}
pokeclean <- pokemon%>%select(HP, Attack, Defense, "SpAtk"="Sp..Atk","SpDef"="Sp..Def",Speed, Generation, Legendary)
fit_log_all <- glm(Legendary~.,data = pokeclean,family = "binomial")
prob_log_all <- predict(fit_log_all,type = "response")
class_diag(prob_log_all,pokeclean$Legendary)
```

The accuracy of the model is 0.948 which is good. The sensitivity, which is the true positive rate, or the probability of a Pokemon being Legendary if they really are when predicted from all the other variables is 0.584. The specificity, which is the true negative rate, or the probability of a Pokemon being labeled as Legendary when they aren't when predicted from all the other variables is 0.980. The Precision, which is the PPV, or the proportion of Pokemon classified as Legendary that actually are from all the other variables is 0.717. The AUC is 0.979 which means that the probability of a randomly selected Legendary Pokemon has a higher set of stats than a randomly selected non-Legendary Pokemon. Next, performed a 10-fold CV with the same model and reported average out-of-sample classification diagnostics.

```{R}
library(randomForest) 
fit_rf=randomForest(Legendary~.,data=pokeclean)
class_diag(fit_rf$votes[,2],pokeclean$Legendary)
set.seed(1234)
k=10

data_all<-pokeclean[sample(nrow(pokeclean)),]
folds_all<-cut(seq(1:nrow(pokeclean)),breaks=k,labels=F)

diags_all<-NULL
for(i in 1:k){
  train_all<-data_all[folds_all!=i,]
  test_all<-data_all[folds_all==i,]
  truth_all<-test_all$Legendary
  
  fit_all<-glm(Legendary~.,data=train_all,family = "binomial")
  probs_all<-predict(fit_all,newdata = test_all,type="response")

diags_all<-rbind(diags_all,class_diag(probs_all,truth_all))
}

diags_all%>%summarize_all(mean)
```

The accuracy of the model is 0.944 which is good. The sensitivity, which is the true positive rate, or the probability of a Pokemon being Legendary if they really are when predicted from all the other variables is 0.490. The specificity, which is the true negative rate, or the probability of a Pokemon being labeled as Legendary when they aren't when predicted from all the other variables is 0.985. The Precision, which is the PPV, or the proportion of Pokemon classified as Legendary that actually are from all the other variables was returned as not a number. The AUC is 0.975 which means that the probability of a randomly selected Legendary Pokemon has a higher set of stats than a randomly selected non-Legendary Pokemon. Next I performed LASSO on the same model.

```{R}
library(glmnet)
y<-as.matrix(pokeclean$Legendary)
x<-model.matrix(Legendary~.,data = pokeclean)[,-1]
head(x)
cv<-cv.glmnet(x,y,family="binomial")
{plot(cv$glmnet.fit, "lambda", label=TRUE)
abline(v = log(cv$lambda.1se))
abline(v = log(cv$lambda.min),lty=2)}
lasso <-glmnet(x,y,family = "binomial",lambda = cv$lambda.1se)
coef(lasso)
```

Looking at the LASSO results, all of the variables used are highly predictive variables. Then I performed a 10-fold CV with the variables that LASSO selected.

```{R}
set.seed(1234)
k=10
data_lasso <-pokeclean%>%sample_frac
folds_lasso <-ntile(1:nrow(data_lasso),n=10)
diags_lasso <-NULL
for(i in 1:k){
  train_lasso <-data_lasso[folds_lasso!=i,]
  test_lasso <-data_lasso[folds_lasso==i,]
  truth_lasso <-test_lasso$Legendary
  fit_lasso <- glm(Legendary~.,
                   data=train_lasso,family = "binomial")
  probs_lasso <-predict(fit_lasso,newdata=test_lasso,type="response")
  diags_lasso <-rbind(diags_lasso,class_diag(probs_lasso,truth_lasso))
}
diags_lasso%>%summarize_all(mean)
```

The accuracy of the model is 0.938 which is good, but less than accuracy of the logistic regression. The sensitivity, which is the true positive rate, or the probability of a Pokemon being Legendary if they really are when predicted from all the other variables is 0.524. The specificity, which is the true negative rate, or the probability of a Pokemon being labeled as Legendary when they aren't when predicted from all the other variables is 0.977. The Precision, which is the PPV, or the proportion of Pokemon classified as Legendary that actually are from all the other variables was returned as not a number. The AUC is 0.976 which means that the probability of a randomly selected Legendary Pokemon has a higher set of stats than a randomly selected non-Legendary Pokemon. This is just slightly less than the AUC of the original logistic regression and virtually equal to the AUC from the 10-fold CV without LASSO, which makes sense since the LASSO results said that all of the variables used are highly predictive variables.